{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.datasets import CNNDM, IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 792k/792k [00:00<00:00, 1.39MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torchtext.models import T5Transform\n",
    "\n",
    "padding_idx = 0\n",
    "eos_idx = 1\n",
    "max_seq_len = 512\n",
    "t5_sp_model_path = \"https://download.pytorch.org/models/text/t5_tokenizer_base.model\"\n",
    "\n",
    "transform = T5Transform(\n",
    "    sp_model_path=t5_sp_model_path,\n",
    "    max_seq_len=max_seq_len,\n",
    "    eos_idx=eos_idx,\n",
    "    padding_idx=padding_idx,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.models import T5_BASE_GENERATION\n",
    "transform = T5_BASE_GENERATION.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/text/t5.base.generation.v2.pt\" to C:\\Users\\user/.cache\\torch\\hub\\checkpoints\\t5.base.generation.v2.pt\n",
      "100%|██████████| 945M/945M [00:32<00:00, 30.7MB/s]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5Model(\n",
       "  (token_embeddings): Embedding(32128, 768, padding_idx=0)\n",
       "  (encoder): T5Encoder(\n",
       "    (token_embeddings): Embedding(32128, 768, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0): T5Layer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "          (relative_attention_bias): Embedding(32, 12)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1-11): 11 x T5Layer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): T5LayerNorm()\n",
       "    (dropout1): Dropout(p=0.0, inplace=False)\n",
       "    (dropout2): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): T5Layer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "          (relative_attention_bias): Embedding(32, 12)\n",
       "        )\n",
       "        (cross_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (norm3): T5LayerNorm()\n",
       "        (dropout4): Dropout(p=0.0, inplace=False)\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1-11): 11 x T5Layer(\n",
       "        (self_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (cross_attn): T5MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=False)\n",
       "        )\n",
       "        (norm3): T5LayerNorm()\n",
       "        (dropout4): Dropout(p=0.0, inplace=False)\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        (norm1): T5LayerNorm()\n",
       "        (norm2): T5LayerNorm()\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): T5LayerNorm()\n",
       "    (dropout1): Dropout(p=0.0, inplace=False)\n",
       "    (dropout2): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.models import T5_BASE_GENERATION\n",
    "\n",
    "\n",
    "t5_base = T5_BASE_GENERATION\n",
    "transform = t5_base.transform()\n",
    "model = t5_base.get_model()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.prototype.generate import GenerationUtils\n",
    "\n",
    "sequence_generator = GenerationUtils(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_datapipe = IMDB(split=\"test\")\n",
    "\n",
    "imdb_batch_size = 3\n",
    "task = \"sst2 sentence\"\n",
    "labels = {\"1\": \"negative\", \"2\": \"positive\"}\n",
    "\n",
    "\n",
    "def process_labels(labels, x):\n",
    "    return x[1], labels[str(x[0])]\n",
    "\n",
    "def apply_prefix(task, x):\n",
    "    return f\"{task}: \" + x[0], x[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_datapipe = imdb_datapipe.map(partial(process_labels, labels))\n",
    "imdb_datapipe = imdb_datapipe.map(partial(apply_prefix, task))\n",
    "imdb_datapipe = imdb_datapipe.batch(imdb_batch_size)\n",
    "imdb_datapipe = imdb_datapipe.rows2columnar([\"text\", \"label\"])\n",
    "imdb_dataloader = DataLoader(imdb_datapipe, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'text': ['sst2 sentence: I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn\\'t match the background, and painfully one-dimensional characters cannot be overcome with a \\'sci-fi\\' setting. (I\\'m sure there are those of you out there who think Babylon 5 is good sci-fi TV. It\\'s not. It\\'s clichéd and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It\\'s really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it\\'s rubbish as they have to always say \"Gene Roddenberry\\'s Earth...\" otherwise people would not continue watching. Roddenberry\\'s ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.', \"sst2 sentence: Worth the entertainment value of a rental, especially if you like action movies. This one features the usual car chases, fights with the great Van Damme kick style, shooting battles with the 40 shell load shotgun, and even terrorist style bombs. All of this is entertaining and competently handled but there is nothing that really blows you away if you've seen your share before.<br /><br />The plot is made interesting by the inclusion of a rabbit, which is clever but hardly profound. Many of the characters are heavily stereotyped -- the angry veterans, the terrified illegal aliens, the crooked cops, the indifferent feds, the bitchy tough lady station head, the crooked politician, the fat federale who looks like he was typecast as the Mexican in a Hollywood movie from the 1940s. All passably acted but again nothing special.<br /><br />I thought the main villains were pretty well done and fairly well acted. By the end of the movie you certainly knew who the good guys were and weren't. There was an emotional lift as the really bad ones got their just deserts. Very simplistic, but then you weren't expecting Hamlet, right? The only thing I found really annoying was the constant cuts to VDs daughter during the last fight scene.<br /><br />Not bad. Not good. Passable 4.\", \"sst2 sentence: its a totally average film with a few semi-alright action sequences that make the plot seem a little better and remind the viewer of the classic van dam films. parts of the plot don't make sense and seem to be added in to use up time. the end plot is that of a very basic type that doesn't leave the viewer guessing and any twists are obvious from the beginning. the end scene with the flask backs don't make sense as they are added in and seem to have little relevance to the history of van dam's character. not really worth watching again, bit disappointed in the end production, even though it is apparent it was shot on a low budget certain shots and sections in the film are of poor directed quality\"], 'label': ['negative', 'negative', 'negative']})\n"
     ]
    }
   ],
   "source": [
    "for item in imdb_datapipe:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "\n",
      "input_text: sst2 sentence: I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn't match the background, and painfully one-dimensional characters cannot be overcome with a 'sci-fi' setting. (I'm sure there are those of you out there who think Babylon 5 is good sci-fi TV. It's not. It's clichéd and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It's really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it's rubbish as they have to always say \"Gene Roddenberry's Earth...\" otherwise people would not continue watching. Roddenberry's ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.\n",
      "\n",
      "prediction: negative\n",
      "\n",
      "target: negative\n",
      "\n",
      "\n",
      "Example 2:\n",
      "\n",
      "input_text: sst2 sentence: Worth the entertainment value of a rental, especially if you like action movies. This one features the usual car chases, fights with the great Van Damme kick style, shooting battles with the 40 shell load shotgun, and even terrorist style bombs. All of this is entertaining and competently handled but there is nothing that really blows you away if you've seen your share before.<br /><br />The plot is made interesting by the inclusion of a rabbit, which is clever but hardly profound. Many of the characters are heavily stereotyped -- the angry veterans, the terrified illegal aliens, the crooked cops, the indifferent feds, the bitchy tough lady station head, the crooked politician, the fat federale who looks like he was typecast as the Mexican in a Hollywood movie from the 1940s. All passably acted but again nothing special.<br /><br />I thought the main villains were pretty well done and fairly well acted. By the end of the movie you certainly knew who the good guys were and weren't. There was an emotional lift as the really bad ones got their just deserts. Very simplistic, but then you weren't expecting Hamlet, right? The only thing I found really annoying was the constant cuts to VDs daughter during the last fight scene.<br /><br />Not bad. Not good. Passable 4.\n",
      "\n",
      "prediction: negative\n",
      "\n",
      "target: negative\n",
      "\n",
      "\n",
      "Example 3:\n",
      "\n",
      "input_text: sst2 sentence: its a totally average film with a few semi-alright action sequences that make the plot seem a little better and remind the viewer of the classic van dam films. parts of the plot don't make sense and seem to be added in to use up time. the end plot is that of a very basic type that doesn't leave the viewer guessing and any twists are obvious from the beginning. the end scene with the flask backs don't make sense as they are added in and seem to have little relevance to the history of van dam's character. not really worth watching again, bit disappointed in the end production, even though it is apparent it was shot on a low budget certain shots and sections in the film are of poor directed quality\n",
      "\n",
      "prediction: negative\n",
      "\n",
      "target: negative\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(imdb_dataloader))\n",
    "input_text = batch[\"text\"]\n",
    "target = batch[\"label\"]\n",
    "beam_size = 1\n",
    "\n",
    "model_input = transform(input_text)\n",
    "model_output = sequence_generator.generate(model_input, eos_idx=eos_idx, num_beams=beam_size)\n",
    "output_text = transform.decode(model_output.tolist())\n",
    "\n",
    "for i in range(imdb_batch_size):\n",
    "    print(f\"Example {i+1}:\\n\")\n",
    "    print(f\"input_text: {input_text[i]}\\n\")\n",
    "    print(f\"prediction: {output_text[i]}\\n\")\n",
    "    print(f\"target: {target[i]}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = transform(['sst2 sentence: WTO reaches agreement and extends tariff exemption for e-commerce for another two years'])\n",
    "model_output = sequence_generator.generate(model_input, eos_idx=eos_idx, num_beams=beam_size)\n",
    "output_text = transform.decode(model_output.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import Multi30k\n",
    "\n",
    "multi_batch_size = 5\n",
    "language_pair = (\"en\", \"de\")\n",
    "multi_datapipe = Multi30k(split=\"train\", language_pair=language_pair)\n",
    "task = \"translate English to Portuguese\"\n",
    "\n",
    "multi_datapipe = multi_datapipe.map(partial(apply_prefix, task))\n",
    "multi_datapipe = multi_datapipe.batch(multi_batch_size)\n",
    "multi_datapipe = multi_datapipe.rows2columnar([\"english\", \"german\"])\n",
    "multi_dataloader = DataLoader(multi_datapipe, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "\n",
      "input_text: translate English to Portuguese: Two young, White males are outside near many bushes.\n",
      "\n",
      "prediction: Zwei junge, weiße Männchen sind draußen in der Nähe vieler Büsche.\n",
      "\n",
      "target: Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\n",
      "\n",
      "\n",
      "Example 2:\n",
      "\n",
      "input_text: translate English to Portuguese: Several men in hard hats are operating a giant pulley system.\n",
      "\n",
      "prediction: Mehrere Männer mit harten Hüten betreiben ein riesiges Zugsystem.\n",
      "\n",
      "target: Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.\n",
      "\n",
      "\n",
      "Example 3:\n",
      "\n",
      "input_text: translate English to Portuguese: A little girl climbing into a wooden playhouse.\n",
      "\n",
      "prediction: Ein kleines Mädchen klettert in ein Holzspielhaus.\n",
      "\n",
      "target: Ein kleines Mädchen klettert in ein Spielhaus aus Holz.\n",
      "\n",
      "\n",
      "Example 4:\n",
      "\n",
      "input_text: translate English to Portuguese: A man in a blue shirt is standing on a ladder cleaning a window.\n",
      "\n",
      "prediction: Ein Mann in einem blauen Hemd steht auf einer Leiter, die ein Fenster säubert.\n",
      "\n",
      "target: Ein Mann in einem blauen Hemd steht auf einer Leiter und putzt ein Fenster.\n",
      "\n",
      "\n",
      "Example 5:\n",
      "\n",
      "input_text: translate English to Portuguese: Two men are at the stove preparing food.\n",
      "\n",
      "prediction: Zwei Männer sind am Ofen, um Lebensmittel zuzubereiten.\n",
      "\n",
      "target: Zwei Männer stehen am Herd und bereiten Essen zu.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(multi_dataloader))\n",
    "input_text = batch[\"english\"]\n",
    "target = batch[\"german\"]\n",
    "\n",
    "model_input = transform(input_text)\n",
    "model_output = sequence_generator.generate(model_input, eos_idx=eos_idx, num_beams=beam_size)\n",
    "output_text = transform.decode(model_output.tolist())\n",
    "\n",
    "for i in range(multi_batch_size):\n",
    "    print(f\"Example {i+1}:\\n\")\n",
    "    print(f\"input_text: {input_text[i]}\\n\")\n",
    "    print(f\"prediction: {output_text[i]}\\n\")\n",
    "    print(f\"target: {target[i]}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = transform(['translate Geman to English: I love you'])\n",
    "model_output = sequence_generator.generate(model_input, eos_idx=eos_idx, num_beams=beam_size)\n",
    "output_text = transform.decode(model_output.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ich liebe dich']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
